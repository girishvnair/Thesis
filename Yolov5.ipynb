{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1ab09f4",
   "metadata": {},
   "source": [
    "# Yolov5 - Object Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f20a433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paperspace/jupyter_dir/yolov5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/ultralytics/yolov5  # clone\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt  # install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aba478b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 üöÄ v6.1-195-gb52fd48 Python-3.8.10 torch-1.11.0+cu102 CUDA:0 (Quadro M4000, 8127MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete ‚úÖ (8 CPUs, 29.4 GB RAM, 14.7/98.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5\n",
    "%pip install -qr requirements.txt\n",
    "import torch\n",
    "import utils\n",
    "display = utils.notebook_init() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da4a1f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_NOTEBOOK_NAME=\"YoloV5\"\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_NOTEBOOK_NAME=\"YoloV5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b2b44a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgirishvnair\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logging\n",
    "%pip install -q wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b7778a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to /home/paperspace/.cache/torch/hub/master.zip\n",
      "YOLOv5 üöÄ v6.1-195-gb52fd48 Python-3.8.10 torch-1.11.0+cu102 CUDA:0 (Quadro M4000, 8127MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5n - yolov5x6, custom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f8999f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgirishvnair\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=coco128.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=7, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 80 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.1-195-gb52fd48 Python-3.8.10 torch-1.11.0+cu102 CUDA:0 (Quadro M4000, 8127MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/paperspace/jupyter_dir/yolov5/wandb/run-20220703_193355-2cttp3dc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwobbly-sunset-4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/girishvnair/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/girishvnair/YOLOv5/runs/2cttp3dc\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 270 layers, 7235389 parameters, 7235389 gradients, 16.5 GFLOPs\n",
      "\n",
      "Transferred 349/349 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/paperspace/jupyter_dir/datasets/coco128/labels/train2017.\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<00:00, 1291.2\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/paperspace/jupyter_dir/datasets/coco128/labels/train2017.ca\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<00:00, 338.88it\u001b[0m\n",
      "Plotting labels to runs/train/exp5/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.27 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp5\u001b[0m\n",
      "Starting training for 7 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/6     3.37G   0.04609    0.0626   0.01898       260       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        128        929      0.733      0.628      0.716      0.467\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/6      4.5G   0.04464   0.06903   0.01716       210       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        128        929       0.75      0.654      0.744      0.479\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/6      4.5G   0.04485   0.06414   0.01611       269       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        128        929      0.812       0.65      0.763      0.492\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       3/6      4.5G   0.04478   0.06041   0.01534       190       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        128        929      0.818      0.642      0.754      0.495\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       4/6      4.5G   0.04459   0.06369   0.01435       149       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        128        929      0.809      0.662      0.765      0.505\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       5/6      4.5G   0.04413     0.067   0.01374       218       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        128        929      0.792      0.687      0.776      0.514\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       6/6      4.5G   0.04236   0.05608   0.01467       155       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        128        929      0.796      0.682      0.777      0.522\n",
      "\n",
      "7 epochs completed in 0.025 hours.\n",
      "Optimizer stripped from runs/train/exp5/weights/last.pt, 14.9MB\n",
      "Optimizer stripped from runs/train/exp5/weights/best.pt, 14.9MB\n",
      "\n",
      "Validating runs/train/exp5/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7225885 parameters, 0 gradients, 16.5 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@WARNING: NMS time limit 1.060s exceeded\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@WARNING: NMS time limit 1.060s exceeded\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        128        837      0.801      0.689      0.783      0.528\n",
      "              person        128        222      0.887      0.706      0.824      0.531\n",
      "             bicycle        128          6      0.714      0.833      0.836      0.431\n",
      "                 car        128         45      0.667      0.489      0.557      0.252\n",
      "          motorcycle        128          5          1      0.918      0.995      0.863\n",
      "            airplane        128          5      0.972          1      0.995      0.864\n",
      "                 bus        128          7      0.765      0.714      0.785      0.668\n",
      "               train        128          2          1      0.788      0.995      0.448\n",
      "               truck        128         12      0.772        0.5      0.614      0.361\n",
      "                boat        128          5          1      0.413       0.63      0.168\n",
      "       traffic light        128         14      0.792      0.286      0.383      0.195\n",
      "           stop sign        128          2      0.719          1      0.995      0.846\n",
      "               bench        128          8      0.688      0.555      0.696      0.333\n",
      "                bird        128          8       0.93          1      0.995       0.65\n",
      "                 cat        128          3          1      0.558      0.995      0.702\n",
      "                 dog        128          4          1      0.724      0.945      0.728\n",
      "               horse        128          2      0.835          1      0.995      0.622\n",
      "            elephant        128         15          1      0.901      0.937      0.748\n",
      "                bear        128          1      0.721          1      0.995      0.995\n",
      "               zebra        128          4      0.886          1      0.995      0.966\n",
      "             giraffe        128          9      0.994      0.778      0.955      0.598\n",
      "            backpack        128          4      0.911        0.5      0.684      0.404\n",
      "            umbrella        128         18      0.712      0.833       0.83       0.47\n",
      "             handbag        128         16      0.902      0.312      0.492      0.231\n",
      "                 tie        128          3      0.586          1      0.995      0.863\n",
      "            suitcase        128          4      0.779          1      0.995      0.547\n",
      "             frisbee        128          3      0.794      0.667      0.673      0.623\n",
      "                skis        128          1      0.734          1      0.995      0.497\n",
      "           snowboard        128          7          1      0.835      0.883       0.53\n",
      "         sports ball        128          6      0.489        0.5       0.58       0.26\n",
      "                kite        128         10       0.52        0.7       0.61      0.239\n",
      "        baseball bat        128          4      0.562       0.25      0.456      0.207\n",
      "      baseball glove        128          7      0.576      0.429      0.463        0.3\n",
      "          skateboard        128          4      0.814       0.75      0.836      0.515\n",
      "       tennis racket        128          7      0.832      0.707      0.669      0.374\n",
      "              bottle        128         18       0.72      0.431      0.704      0.367\n",
      "          wine glass        128         16      0.683      0.938      0.914      0.493\n",
      "                 cup        128         36       0.76      0.889      0.889      0.546\n",
      "                fork        128          6       0.92      0.333      0.533      0.321\n",
      "               knife        128         16      0.808      0.527      0.708      0.403\n",
      "               spoon        128         22      0.656      0.455      0.551      0.336\n",
      "                bowl        128         24      0.943      0.686      0.774      0.581\n",
      "              banana        128          1       0.93          1      0.995      0.298\n",
      "            sandwich        128          2          1          0      0.497      0.473\n",
      "            broccoli        128         10       0.49        0.4      0.463       0.31\n",
      "              carrot        128         24      0.724      0.833      0.833      0.567\n",
      "             hot dog        128          2      0.612          1      0.828      0.795\n",
      "               pizza        128          5      0.929        0.8      0.962      0.728\n",
      "               donut        128         14      0.614          1       0.97      0.847\n",
      "                cake        128          4      0.883          1      0.995      0.859\n",
      "               chair        128         35      0.547      0.657      0.634      0.336\n",
      "               couch        128          6          1      0.652      0.904        0.6\n",
      "        potted plant        128         10      0.734      0.828      0.871      0.494\n",
      "                 bed        128          3          1          0      0.995      0.549\n",
      "        dining table        128         13      0.836      0.393      0.647      0.403\n",
      "              toilet        128          2      0.858          1      0.995      0.821\n",
      "                  tv        128          2      0.842          1      0.995      0.895\n",
      "              laptop        128          3          1      0.521      0.863      0.586\n",
      "               mouse        128          2          1          0      0.284      0.097\n",
      "              remote        128          8      0.957      0.625      0.671      0.558\n",
      "          cell phone        128          5      0.829        0.2       0.35     0.0559\n",
      "           microwave        128          3      0.863          1      0.995      0.768\n",
      "                oven        128          4      0.699       0.75      0.686      0.451\n",
      "                sink        128          5      0.448      0.338      0.409      0.314\n",
      "        refrigerator        128          4      0.611       0.75      0.758      0.553\n",
      "                book        128         28      0.584       0.25      0.339      0.173\n",
      "               clock        128          7      0.896      0.857      0.937      0.785\n",
      "                vase        128          1       0.63          1      0.995      0.895\n",
      "          teddy bear        128         18      0.767      0.778      0.814      0.528\n",
      "          toothbrush        128          5      0.924          1      0.995      0.633\n",
      "Results saved to \u001b[1mruns/train/exp5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñÅ‚ñÇ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñà‚ñá‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÖ‚ñá‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñÅ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÅ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.77708\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.52225\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.79643\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.68185\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.78309\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.52829\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.80067\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.68893\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01467\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.05608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.0387\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.00675\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.03488\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00083\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00083\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.04583\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mwobbly-sunset-4\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/girishvnair/YOLOv5/runs/2cttp3dc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 241 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220703_193355-2cttp3dc/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train YOLOv5s on COCO128 for 3 epochs\n",
    "!python train.py --img 640 --batch 16 --epochs 7 --data coco128.yaml --weights yolov5s.pt --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5441a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2e157f6440442ba192f7ddad9d9d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/780M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download COCO val\n",
    "torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')\n",
    "!unzip -q tmp.zip -d ../datasets && rm tmp.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fbe3806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgirishvnair\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=coco128.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 80 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "YOLOv5 üöÄ v6.1-195-gb52fd48 Python-3.8.10 torch-1.11.0+cu102 CUDA:0 (Quadro M4000, 8127MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/paperspace/jupyter_dir/yolov5/wandb/run-20220703_192845-1u5uxhdl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhonest-firefly-3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/girishvnair/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/girishvnair/YOLOv5/runs/1u5uxhdl\u001b[0m\n",
      "YOLOv5 temporarily requires wandb version 0.12.10 or below. Some features may not work as expected.\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 270 layers, 7235389 parameters, 7235389 gradients, 16.5 GFLOPs\n",
      "\n",
      "Transferred 349/349 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/paperspace/jupyter_dir/datasets/coco128/labels/train2017.\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<00:00, 1288.9\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/paperspace/jupyter_dir/datasets/coco128/labels/train2017.ca\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<00:00, 339.64it\u001b[0m\n",
      "Plotting labels to runs/train/exp4/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.27 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp4\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       0/2     3.37G   0.04609    0.0626   0.01898       260       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        128        929      0.734      0.627      0.716      0.467\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       1/2      4.5G   0.04465   0.06906   0.01721       210       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        128        929      0.741      0.651      0.743       0.48\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "       2/2      4.5G   0.04489   0.06444   0.01633       269       640: 100%|‚ñà‚ñà‚ñà\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        128        929      0.779      0.654      0.758      0.494\n",
      "\n",
      "3 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from runs/train/exp4/weights/last.pt, 14.9MB\n",
      "Optimizer stripped from runs/train/exp4/weights/best.pt, 14.9MB\n",
      "\n",
      "Validating runs/train/exp4/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7225885 parameters, 0 gradients, 16.5 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@WARNING: NMS time limit 1.060s exceeded\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        128        929      0.779      0.654      0.758      0.494\n",
      "              person        128        254      0.866       0.71      0.819      0.518\n",
      "             bicycle        128          6      0.764      0.546      0.623      0.376\n",
      "                 car        128         46      0.613      0.552      0.557      0.214\n",
      "          motorcycle        128          5          1       0.96      0.995      0.678\n",
      "            airplane        128          6      0.937          1      0.995      0.751\n",
      "                 bus        128          7      0.818      0.714      0.723      0.642\n",
      "               train        128          3      0.968      0.667       0.83      0.551\n",
      "               truck        128         12      0.545      0.417      0.482      0.248\n",
      "                boat        128          6          1      0.318      0.418     0.0863\n",
      "       traffic light        128         14      0.669      0.289      0.372      0.217\n",
      "           stop sign        128          2      0.788          1      0.995      0.796\n",
      "               bench        128          9      0.687      0.444      0.609      0.228\n",
      "                bird        128         16      0.954          1      0.995      0.666\n",
      "                 cat        128          4      0.878          1      0.995      0.797\n",
      "                 dog        128          9          1      0.658       0.89      0.646\n",
      "               horse        128          2      0.814          1      0.995      0.647\n",
      "            elephant        128         17      0.955      0.882      0.932       0.69\n",
      "                bear        128          1      0.677          1      0.995      0.895\n",
      "               zebra        128          4      0.868          1      0.995      0.947\n",
      "             giraffe        128          9       0.88          1      0.995      0.644\n",
      "            backpack        128          6      0.921      0.667      0.808      0.333\n",
      "            umbrella        128         18      0.808      0.667      0.867      0.504\n",
      "             handbag        128         19      0.759      0.211      0.339      0.157\n",
      "                 tie        128          7      0.775      0.714      0.822      0.482\n",
      "            suitcase        128          4      0.485          1      0.912      0.546\n",
      "             frisbee        128          5      0.696        0.8        0.8       0.74\n",
      "                skis        128          1      0.729          1      0.995      0.398\n",
      "           snowboard        128          7      0.853      0.714      0.867      0.553\n",
      "         sports ball        128          6      0.612      0.667      0.603      0.293\n",
      "                kite        128         10      0.856      0.597      0.625      0.258\n",
      "        baseball bat        128          4      0.397       0.25      0.401      0.171\n",
      "      baseball glove        128          7        0.7      0.429      0.467      0.322\n",
      "          skateboard        128          5          1      0.571      0.848      0.513\n",
      "       tennis racket        128          7      0.752      0.429      0.626      0.295\n",
      "              bottle        128         18       0.59      0.401      0.575      0.278\n",
      "          wine glass        128         16      0.652          1      0.925      0.499\n",
      "                 cup        128         36       0.79      0.806      0.847      0.515\n",
      "                fork        128          6      0.984      0.333      0.439      0.302\n",
      "               knife        128         16      0.756      0.581      0.679      0.404\n",
      "               spoon        128         22      0.828      0.437      0.593      0.336\n",
      "                bowl        128         28      0.784       0.65      0.753      0.513\n",
      "              banana        128          1        0.8          1      0.995     0.0995\n",
      "            sandwich        128          2          1          0      0.606      0.545\n",
      "              orange        128          4      0.918          1      0.995      0.691\n",
      "            broccoli        128         11       0.37      0.455      0.467      0.336\n",
      "              carrot        128         24      0.745      0.542       0.73      0.501\n",
      "             hot dog        128          2      0.561          1      0.828      0.712\n",
      "               pizza        128          5      0.803      0.819      0.962      0.677\n",
      "               donut        128         14      0.693          1      0.981      0.846\n",
      "                cake        128          4      0.865          1      0.995      0.858\n",
      "               chair        128         35      0.636      0.648      0.615      0.301\n",
      "               couch        128          6       0.84        0.5      0.806      0.514\n",
      "        potted plant        128         14      0.737      0.786      0.835      0.471\n",
      "                 bed        128          3          1          0      0.806      0.557\n",
      "        dining table        128         13      0.863      0.487      0.604      0.404\n",
      "              toilet        128          2      0.925          1      0.995      0.846\n",
      "                  tv        128          2      0.678          1      0.995      0.821\n",
      "              laptop        128          3          1          0       0.83      0.532\n",
      "               mouse        128          2          1          0     0.0936     0.0468\n",
      "              remote        128          8          1      0.612       0.66      0.534\n",
      "          cell phone        128          8      0.727      0.375      0.469      0.235\n",
      "           microwave        128          3      0.796          1      0.995      0.734\n",
      "                oven        128          5      0.433        0.4       0.44       0.29\n",
      "                sink        128          6      0.349      0.167      0.308      0.213\n",
      "        refrigerator        128          5      0.644        0.8      0.804      0.532\n",
      "                book        128         29      0.602      0.207      0.296       0.16\n",
      "               clock        128          9      0.784      0.889      0.888      0.692\n",
      "                vase        128          2       0.47          1      0.995      0.895\n",
      "            scissors        128          1          1          0      0.995      0.199\n",
      "          teddy bear        128         21      0.853      0.667      0.825      0.524\n",
      "          toothbrush        128          5      0.808          1      0.995       0.66\n",
      "Results saved to \u001b[1mruns/train/exp4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ‚ñÅ‚ñÖ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ‚ñÅ‚ñÑ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ‚ñÅ‚ñÇ‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ‚ñÅ‚ñá‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ‚ñà‚ñÅ‚ñÇ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ‚ñà‚ñÉ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ‚ñÅ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ‚ñà‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ‚ñà‚ñÉ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ‚ñà‚ñÜ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ‚ñÅ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ‚ñÅ‚ñà‚ñÉ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ‚ñà‚ñÖ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.7582\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.49446\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.77912\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.65399\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.75781\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.49411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.77898\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.65396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04489\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.06444\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.00821\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.03638\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.07778\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mhonest-firefly-3\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/girishvnair/YOLOv5/runs/1u5uxhdl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 113 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220703_192845-1u5uxhdl/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b166d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f3931d46776d8dd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f3931d46776d8dd\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --host 0.0.0.0 --logdir ./runs/val/exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6976303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plots import plot_results \n",
    "plot_results('/home/paperspace/jupyter_dir/yolov5/runs/train/exp2/results.csv')  # plot 'results.csv' as 'results.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f982817a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
